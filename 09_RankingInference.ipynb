{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning a language model to predict documents ranking\n",
    "\n",
    "In this notebook, we'll attempt to finetune a pre-trained language model in the task of ranking prediction.\n",
    "We'll use the CORD-19 dataset compiled by the Allen Institute for Artificial Intelligence, which comprehends more than 200.000 papers related to the Coronavirus pandemic.\n",
    "\n",
    "We'll build the references graph and use the PageRank static ranking algorithm to assess the relevance of each paper.\n",
    "Then, we'll put a classifier head on top of a pre-trained language model and finetune it using the ranking scores as supervision in a semi-supervised way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the references graph\n",
    "\n",
    "Refer to the following notebooks to inspect the source code used to build the references graph.\n",
    "\n",
    "- https://github.com/Inria-Chile/risotto/blob/master/01_references.ipynb\n",
    "- https://github.com/Inria-Chile/risotto/blob/master/05_cook_artifacts.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pagerank</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>country</th>\n",
       "      <th>sha</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>...</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>mag_id</th>\n",
       "      <th>who_covidence_id</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>pdf_json_files</th>\n",
       "      <th>pmc_json_files</th>\n",
       "      <th>url</th>\n",
       "      <th>s2_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cord_uid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ug7v899j</th>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>d1aafb70c066a2068b02786f8929fd9c900897fb</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Clinical features of culture-proven Mycoplasma...</td>\n",
       "      <td>10.1186/1471-2334-1-6</td>\n",
       "      <td>PMC35282</td>\n",
       "      <td>1.14726e+07</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>...</td>\n",
       "      <td>2001-07-04</td>\n",
       "      <td>Madani, Tariq A; Al-Ghamdi, Aisha A</td>\n",
       "      <td>BMC Infect Dis</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>document_parses/pdf_json/d1aafb70c066a2068b027...</td>\n",
       "      <td>document_parses/pmc_json/PMC35282.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02tnwd4m</th>\n",
       "      <td>0.030459</td>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>USA</td>\n",
       "      <td>6b0567729c2143a66d737eb0a2f63f2dce2e5a7d</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Nitric oxide: a pro-inflammatory mediator in l...</td>\n",
       "      <td>10.1186/rr14</td>\n",
       "      <td>PMC59543</td>\n",
       "      <td>1.1668e+07</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>...</td>\n",
       "      <td>2000-08-15</td>\n",
       "      <td>Vliet, Albert van der; Eiserich, Jason P; Cros...</td>\n",
       "      <td>Respir Res</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>document_parses/pdf_json/6b0567729c2143a66d737...</td>\n",
       "      <td>document_parses/pmc_json/PMC59543.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ejv2xln0</th>\n",
       "      <td>0.215860</td>\n",
       "      <td>Washington University School of Medicine</td>\n",
       "      <td>USA</td>\n",
       "      <td>06ced00a5fc04215949aa72528f2eeaae1d58927</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Surfactant protein-D and pulmonary host defense</td>\n",
       "      <td>10.1186/rr19</td>\n",
       "      <td>PMC59549</td>\n",
       "      <td>1.1668e+07</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>...</td>\n",
       "      <td>2000-08-25</td>\n",
       "      <td>Crouch, Erika C</td>\n",
       "      <td>Respir Res</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>document_parses/pdf_json/06ced00a5fc04215949aa...</td>\n",
       "      <td>document_parses/pmc_json/PMC59549.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2b73a28n</th>\n",
       "      <td>0.043255</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>348055649b6b8cf2b9a376498df9bf41f7123605</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Role of endothelin-1 in lung disease</td>\n",
       "      <td>10.1186/rr44</td>\n",
       "      <td>PMC59574</td>\n",
       "      <td>1.16869e+07</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>...</td>\n",
       "      <td>2001-02-22</td>\n",
       "      <td>Fagan, Karen A; McMurtry, Ivan F; Rodman, David M</td>\n",
       "      <td>Respir Res</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>document_parses/pdf_json/348055649b6b8cf2b9a37...</td>\n",
       "      <td>document_parses/pmc_json/PMC59574.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9785vg6d</th>\n",
       "      <td>0.036417</td>\n",
       "      <td>National Institutes of Health (Laboratory of H...</td>\n",
       "      <td>USA</td>\n",
       "      <td>5f48792a5fa08bed9f56016f4981ae2ca6031b32</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Gene expression in epithelial cells in respons...</td>\n",
       "      <td>10.1186/rr61</td>\n",
       "      <td>PMC59580</td>\n",
       "      <td>1.16869e+07</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>...</td>\n",
       "      <td>2001-05-11</td>\n",
       "      <td>Domachowske, Joseph B; Bonville, Cynthia A; Ro...</td>\n",
       "      <td>Respir Res</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>document_parses/pdf_json/5f48792a5fa08bed9f560...</td>\n",
       "      <td>document_parses/pmc_json/PMC59580.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pagerank                                        affiliation country  \\\n",
       "cord_uid                                                                        \n",
       "ug7v899j  0.000000                                                              \n",
       "02tnwd4m  0.030459                University of Alabama at Birmingham     USA   \n",
       "ejv2xln0  0.215860           Washington University School of Medicine     USA   \n",
       "2b73a28n  0.043255                                                              \n",
       "9785vg6d  0.036417  National Institutes of Health (Laboratory of H...     USA   \n",
       "\n",
       "                                               sha source_x  \\\n",
       "cord_uid                                                      \n",
       "ug7v899j  d1aafb70c066a2068b02786f8929fd9c900897fb      PMC   \n",
       "02tnwd4m  6b0567729c2143a66d737eb0a2f63f2dce2e5a7d      PMC   \n",
       "ejv2xln0  06ced00a5fc04215949aa72528f2eeaae1d58927      PMC   \n",
       "2b73a28n  348055649b6b8cf2b9a376498df9bf41f7123605      PMC   \n",
       "9785vg6d  5f48792a5fa08bed9f56016f4981ae2ca6031b32      PMC   \n",
       "\n",
       "                                                      title  \\\n",
       "cord_uid                                                      \n",
       "ug7v899j  Clinical features of culture-proven Mycoplasma...   \n",
       "02tnwd4m  Nitric oxide: a pro-inflammatory mediator in l...   \n",
       "ejv2xln0    Surfactant protein-D and pulmonary host defense   \n",
       "2b73a28n               Role of endothelin-1 in lung disease   \n",
       "9785vg6d  Gene expression in epithelial cells in respons...   \n",
       "\n",
       "                            doi     pmcid    pubmed_id license  ...  \\\n",
       "cord_uid                                                        ...   \n",
       "ug7v899j  10.1186/1471-2334-1-6  PMC35282  1.14726e+07   no-cc  ...   \n",
       "02tnwd4m           10.1186/rr14  PMC59543   1.1668e+07   no-cc  ...   \n",
       "ejv2xln0           10.1186/rr19  PMC59549   1.1668e+07   no-cc  ...   \n",
       "2b73a28n           10.1186/rr44  PMC59574  1.16869e+07   no-cc  ...   \n",
       "9785vg6d           10.1186/rr61  PMC59580  1.16869e+07   no-cc  ...   \n",
       "\n",
       "         publish_time                                            authors  \\\n",
       "cord_uid                                                                   \n",
       "ug7v899j   2001-07-04                Madani, Tariq A; Al-Ghamdi, Aisha A   \n",
       "02tnwd4m   2000-08-15  Vliet, Albert van der; Eiserich, Jason P; Cros...   \n",
       "ejv2xln0   2000-08-25                                    Crouch, Erika C   \n",
       "2b73a28n   2001-02-22  Fagan, Karen A; McMurtry, Ivan F; Rodman, David M   \n",
       "9785vg6d   2001-05-11  Domachowske, Joseph B; Bonville, Cynthia A; Ro...   \n",
       "\n",
       "                 journal mag_id who_covidence_id arxiv_id  \\\n",
       "cord_uid                                                    \n",
       "ug7v899j  BMC Infect Dis    N/A              N/A      N/A   \n",
       "02tnwd4m      Respir Res    N/A              N/A      N/A   \n",
       "ejv2xln0      Respir Res    N/A              N/A      N/A   \n",
       "2b73a28n      Respir Res    N/A              N/A      N/A   \n",
       "9785vg6d      Respir Res    N/A              N/A      N/A   \n",
       "\n",
       "                                             pdf_json_files  \\\n",
       "cord_uid                                                      \n",
       "ug7v899j  document_parses/pdf_json/d1aafb70c066a2068b027...   \n",
       "02tnwd4m  document_parses/pdf_json/6b0567729c2143a66d737...   \n",
       "ejv2xln0  document_parses/pdf_json/06ced00a5fc04215949aa...   \n",
       "2b73a28n  document_parses/pdf_json/348055649b6b8cf2b9a37...   \n",
       "9785vg6d  document_parses/pdf_json/5f48792a5fa08bed9f560...   \n",
       "\n",
       "                                      pmc_json_files  \\\n",
       "cord_uid                                               \n",
       "ug7v899j  document_parses/pmc_json/PMC35282.xml.json   \n",
       "02tnwd4m  document_parses/pmc_json/PMC59543.xml.json   \n",
       "ejv2xln0  document_parses/pmc_json/PMC59549.xml.json   \n",
       "2b73a28n  document_parses/pmc_json/PMC59574.xml.json   \n",
       "9785vg6d  document_parses/pmc_json/PMC59580.xml.json   \n",
       "\n",
       "                                                        url s2_id  \n",
       "cord_uid                                                           \n",
       "ug7v899j  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3...   N/A  \n",
       "02tnwd4m  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...   N/A  \n",
       "ejv2xln0  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...   N/A  \n",
       "2b73a28n  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...   N/A  \n",
       "9785vg6d  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...   N/A  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Index(['pagerank', 'affiliation', 'country', 'sha', 'source_x', 'title', 'doi',\n",
       "        'pmcid', 'pubmed_id', 'license', 'abstract', 'publish_time', 'authors',\n",
       "        'journal', 'mag_id', 'who_covidence_id', 'arxiv_id', 'pdf_json_files',\n",
       "        'pmc_json_files', 'url', 's2_id'],\n",
       "       dtype='object'),\n",
       " (62427, 21))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from risotto.artifacts import load_papers_artifact\n",
    "\n",
    "\n",
    "def get_papers():\n",
    "    papers = load_papers_artifact().fillna(\"N/A\")\n",
    "    papers[\"pagerank\"] = np.log(papers[\"pagerank\"])\n",
    "    mean_pagerank = papers[\"pagerank\"].mean()\n",
    "    std_pagerank = papers[\"pagerank\"].std()\n",
    "    papers[\"pagerank\"] = (papers[\"pagerank\"] - mean_pagerank) / std_pagerank\n",
    "    min_pagerank = papers[\"pagerank\"].min()\n",
    "    max_pagerank = papers[\"pagerank\"].max()\n",
    "    papers[\"pagerank\"] = (papers[\"pagerank\"] - min_pagerank) / (max_pagerank - min_pagerank)\n",
    "    return papers\n",
    "\n",
    "papers = get_papers()\n",
    "display(papers.head())\n",
    "papers.columns, papers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning a pre--trained language model\n",
    "\n",
    "We'll implement our model using PyTorch Lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: transformers in ./venv-risotto/lib/python3.8/site-packages (3.0.2)\n",
      "Requirement already up-to-date: torch in ./venv-risotto/lib/python3.8/site-packages (1.6.0)\n",
      "Requirement already up-to-date: pytorch-lightning in ./venv-risotto/lib/python3.8/site-packages (0.8.5)\n",
      "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in ./venv-risotto/lib/python3.8/site-packages (from transformers) (2020.6.8)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in ./venv-risotto/lib/python3.8/site-packages (from transformers) (4.47.0)\n",
      "Requirement already satisfied, skipping upgrade: tokenizers==0.8.1.rc1 in ./venv-risotto/lib/python3.8/site-packages (from transformers) (0.8.1rc1)\n",
      "Requirement already satisfied, skipping upgrade: numpy in ./venv-risotto/lib/python3.8/site-packages (from transformers) (1.19.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging in ./venv-risotto/lib/python3.8/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: sacremoses in ./venv-risotto/lib/python3.8/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied, skipping upgrade: sentencepiece!=0.1.92 in ./venv-risotto/lib/python3.8/site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied, skipping upgrade: filelock in ./venv-risotto/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied, skipping upgrade: requests in ./venv-risotto/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: future in ./venv-risotto/lib/python3.8/site-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML>=5.1 in ./venv-risotto/lib/python3.8/site-packages (from pytorch-lightning) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard>=1.14 in ./venv-risotto/lib/python3.8/site-packages (from pytorch-lightning) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: six in ./venv-risotto/lib/python3.8/site-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in ./venv-risotto/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: click in ./venv-risotto/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib in ./venv-risotto/lib/python3.8/site-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in ./venv-risotto/lib/python3.8/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./venv-risotto/lib/python3.8/site-packages (from requests->transformers) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in ./venv-risotto/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in ./venv-risotto/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in ./venv-risotto/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning) (47.1.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in ./venv-risotto/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.4 in ./venv-risotto/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.24.3 in ./venv-risotto/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning) (1.30.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in ./venv-risotto/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in ./venv-risotto/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in ./venv-risotto/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in ./venv-risotto/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning) (3.12.2)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in ./venv-risotto/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in ./venv-risotto/lib/python3.8/site-packages (from tensorboard>=1.14->pytorch-lightning) (1.20.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in ./venv-risotto/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in ./venv-risotto/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (4.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in ./venv-risotto/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.5\" in ./venv-risotto/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (3.4.2)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in ./venv-risotto/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in ./venv-risotto/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (0.4.8)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2 is available.\n",
      "You should consider upgrading via the '/Users/rodolfo/repos/risotto/venv-risotto/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers torch pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW\n",
    "\n",
    "\n",
    "class PapersDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self._df = df\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self._df.iloc[idx]\n",
    "        text = item[\"title\"] + \" \" + item[\"abstract\"]\n",
    "        pagerank = item[\"pagerank\"]\n",
    "        return {\n",
    "            \"text\": text,\n",
    "            \"pagerank\": torch.tensor(pagerank, dtype=torch.float)\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._df)\n",
    "        \n",
    "        \n",
    "class RankingPredictor(LightningModule):\n",
    "    def __init__(self, base_model, learning_rate=1e-5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.language_model = AutoModelForSequenceClassification.from_pretrained(base_model)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    \n",
    "    def forward(self, papers):\n",
    "        papers_encoded = self.tokenizer(\n",
    "            papers,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        input_ids = papers_encoded[\"input_ids\"]\n",
    "        attention_mask = papers_encoded[\"attention_mask\"]\n",
    "        outputs = self.language_model(input_ids, attention_mask=attention_mask)\n",
    "        return outputs\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(model.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def loss(self, predicted, target):\n",
    "        predicted_activated = F.softmax(predicted, dim=1)\n",
    "        predicted_sliced = predicted_activated[:,1].squeeze()\n",
    "        mse = F.mse_loss(predicted_sliced, target)\n",
    "        return mse\n",
    "    \n",
    "    def _inference(self, batch, _):\n",
    "        text = batch[\"text\"]\n",
    "        target = batch[\"pagerank\"]\n",
    "        \n",
    "        predicted = self(text)\n",
    "        loss = self.loss(predicted, target)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "        }\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._inference(batch, batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name           | Type                          | Params\n",
      "-----------------------------------------------------------------\n",
      "0 | language_model | BertForSequenceClassification | 109 M \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodolfo/repos/risotto/venv-risotto/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'softmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-6e763214c926>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRankingPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfast_dev_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repos/risotto/venv-risotto/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders)\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_schedulers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_frequencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pretrain_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;31m# callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/risotto/venv-risotto/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_pretrain_routine\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m         \u001b[0;31m# CORE TRAINING LOOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m     def test(\n",
      "\u001b[0;32m~/repos/risotto/venv-risotto/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0;31m# RUN TNG EPOCH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/risotto/venv-risotto/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;31m# TRAINING_STEP + TRAINING_STEP_END\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;31m# ------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;31m# only track outputs when user implements training_epoch_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/risotto/venv-risotto/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    625\u001b[0m                 \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# -------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                 opt_closure_result = self.optimizer_closure(\n\u001b[0m\u001b[1;32m    628\u001b[0m                     \u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                     \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/risotto/venv-risotto/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36moptimizer_closure\u001b[0;34m(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\u001b[0m\n\u001b[1;32m    773\u001b[0m                                                                  opt_idx, hiddens)\n\u001b[1;32m    774\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m                 training_step_output = self.training_forward(split_batch, batch_idx, opt_idx,\n\u001b[0m\u001b[1;32m    776\u001b[0m                                                              hiddens)\n\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/risotto/venv-risotto/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_forward\u001b[0;34m(self, batch, batch_idx, opt_idx, hiddens)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;31m# CPU forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;31m# allow any mode to define training_step_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-67389d888b5c>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-67389d888b5c>\u001b[0m in \u001b[0;36m_inference\u001b[0;34m(self, batch, _)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         return {\n",
      "\u001b[0;32m<ipython-input-27-67389d888b5c>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, predicted, target)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mpredicted_activated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mpredicted_sliced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_activated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_sliced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/risotto/venv-risotto/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0mNote\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mSoftmin\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mSee\u001b[0m \u001b[0msoftmax\u001b[0m \u001b[0mdefinition\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmathematical\u001b[0m \u001b[0mformula\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmin\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0mArguments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'softmax'"
     ]
    }
   ],
   "source": [
    "ds = PapersDataset(papers)\n",
    "dl = DataLoader(\n",
    "    ds,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    ")\n",
    "model = RankingPredictor(\"bert-base-uncased\")\n",
    "trainer = Trainer(fast_dev_run=True)\n",
    "trainer.fit(model, train_dataloader=dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('venv-risotto': venv)",
   "language": "python",
   "name": "python37764bitvenvrisottovenv9536b9e68257405b8ab17e1634210db9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
