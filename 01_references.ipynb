{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='left' style=\"width:29%;overflow:hidden;\">\n",
    "<a href='http://inria.fr'>\n",
    "<img src='https://github.com/lmarti/jupyter_custom/raw/master/imgs/inr_logo_rouge.png' alt='Inria logo' title='Inria logo'/>\n",
    "</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring CORD-19 references\n",
    "\n",
    "> This notebooks explores how much information we can obtain from the citation references of the papers in the COVID-19 Open Research Dataset Challenge (CORD-19).\n",
    "\n",
    "Here we are trying to load the dataset and check:\n",
    "\n",
    "- How many papers can we parse?\n",
    "- How to extract the references?\n",
    "- How many references are also in the CORD-19 dataset?\n",
    "- How many are out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# removing ugly pandas warning in macOS\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*lzma.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from fastprogress.fastprogress import progress_bar\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the CORD-19 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cord19_dataset_folder = \"./datasets/CORD-19-research-challenge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path(cord19_dataset_folder).exists():\n",
    "    print('Good to go')\n",
    "else:\n",
    "    print(f'{data_root} does not exist! Download it using 00_download.ipynb.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading `metadata.csv` file as a pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv(f\"{cord19_dataset_folder}/metadata.csv\", index_col=\"cord_uid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How metadata looks like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_in_metadata_count = len(metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'Total records loaded: {file_in_metadata_count}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(metadata_df[\"pdf_json_files\"].isna() & metadata_df[\"pmc_json_files\"].isna()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each paper is represented by a unique id called `cord_uid`.\n",
    "\n",
    "Meaning of columns:\n",
    "\n",
    "- `sha`: PDF file hash\n",
    "- `source_x`: source repository, e.g. Biorxiv, Elsevier, etc.\n",
    "- `title`: paper title\n",
    "- `doi`, `pmcid`, `pubmed_id`, `Microsoft Academic Paper ID`, `WHO #Covidence`: other document ids\n",
    "- `license`: usage license\n",
    "- `abstract`:plain text abstract\n",
    "- `publish_time`: publish date\n",
    "- `journal`: academic journal of publication, if applicable\n",
    "- `authors`: authors in plain text\n",
    "- `has_pdf_parse`: if PDF parsing is available\n",
    "- `has_pmc_xml_parse`: if PubMed XML is available\n",
    "- `full_text_file`: pointer to the source file in the dataset\n",
    "- `url`: URL to paper online source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells will explore the folders and files structure of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sample_json_file(path):\n",
    "    for _, _, file_names in os.walk(path):\n",
    "        sample_file_name = random.choice(file_names)\n",
    "        file_path = os.path.join(path, sample_file_name)\n",
    "        with open(file_path) as file:\n",
    "            contents = json.load(file)\n",
    "        return list(contents.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_dataset():\n",
    "    cum_sum = 0\n",
    "    for root, folders, files in os.walk(cord19_dataset_folder):\n",
    "        num_folders = len(folders)\n",
    "        num_files = len(files)\n",
    "        if \"json\" in root and num_folders == 0 and num_files > 0:\n",
    "            cum_sum += num_files\n",
    "            print(f\"{root}: {num_files} files\")\n",
    "    return cum_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file_count = walk_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Files in metadata: {file_in_metadata_count}, source files: {source_file_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We have {source_file_count-file_in_metadata_count} files without metadata.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the information found in the Kaggle community site, there are at least two recommended procedures to load the dataset.\n",
    "\n",
    "```python\n",
    "# First method\n",
    "for row in metadata_file:\n",
    "    pmc_id = row[\"pmc_id\"]\n",
    "    if exists pmc_id file in pmc_jsons subfolders:\n",
    "        return pmc_id file\n",
    "    # If `pmc_id` is null or there is no file\n",
    "    sha = row[\"sha\"]\n",
    "    if exists sha file in pdf_jsons subfolders:\n",
    "        return sha file\n",
    "\n",
    "# Second method\n",
    "for pdf file in pdf files:\n",
    "    if pdf file sha not in metadata_file shas:\n",
    "        continue\n",
    "    else:\n",
    "        row = metadata_file row with matching pdf file sha\n",
    "        pmc_id = row[\"pmc_id\"]\n",
    "        if exists pmc_id file in pmc_jsons subfolders:\n",
    "            return pmc_id file\n",
    "        return pdf file\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def get_id_paths_dicts(cls, cord19_dataset_folder):\n",
    "    \"\"\"\n",
    "    DEPRECATED.\n",
    "    This function builds the dictionaries whose keys are identifiers\n",
    "    of some kind of papers (PDF or PMC) and whose values are the paths to\n",
    "    associated files.\n",
    "    \"\"\"\n",
    "    all_files = {}\n",
    "    for root, folders, files in os.walk(cord19_dataset_folder):\n",
    "        num_folders = len(folders)\n",
    "        num_files = len(files)\n",
    "        if cls in root and num_folders == 0 and num_files > 0:\n",
    "            for file_name in files:\n",
    "                _id = file_name.split(\".\")[0]\n",
    "                all_files[_id] = os.path.join(root, file_name)\n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_dict = get_id_paths_dicts(\"pdf\", cord19_dataset_folder)\n",
    "pmc_dict = get_id_paths_dicts(\"pmc\", cord19_dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of PDF files with parse JSON {len(pdf_dict)}')\n",
    "print(f'Number of PMC files with parse JSON {len(pmc_dict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading PDF and PMC papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "class BasePaper:\n",
    "    def __init__(self, metadata_row, file_path):\n",
    "        self._metadata_row = metadata_row\n",
    "        self._file_path = file_path\n",
    "        self._file_contents = self._load_json_contents(file_path)\n",
    "        \n",
    "        self._referenced_by = []\n",
    "        self._references = []\n",
    "    \n",
    "    def __getstate__(self):\n",
    "        \"\"\"\n",
    "        Avoid RecursionErrors by not pickling references.\n",
    "        \"\"\"\n",
    "        state = self.__dict__.copy()\n",
    "        del state[\"_referenced_by\"]\n",
    "        del state[\"_references\"]\n",
    "        return state\n",
    "    \n",
    "    def __setstate__(self, state):\n",
    "        self.__dict__.update(state)\n",
    "        self._referenced_by = []\n",
    "        self._references = []\n",
    "        \n",
    "    @staticmethod\n",
    "    def _load_json_contents(path):\n",
    "        with open(path) as file:\n",
    "            contents = json.load(file)\n",
    "        return contents\n",
    "\n",
    "    @property\n",
    "    def title(self):\n",
    "        return self._metadata_row[\"title\"]\n",
    "        \n",
    "    @property\n",
    "    def authors(self):\n",
    "        return self._metadata_row[\"authors\"]\n",
    "        \n",
    "    @property\n",
    "    def publish_time(self):\n",
    "        return self._metadata_row[\"publish_time\"]\n",
    "        \n",
    "    @property\n",
    "    def abstract(self):\n",
    "        return self._metadata_row[\"abstract\"]\n",
    "        \n",
    "    @property\n",
    "    def bib_entries(self):\n",
    "        return self._file_contents[\"bib_entries\"]\n",
    "    \n",
    "    @property\n",
    "    def doi(self):\n",
    "        return self._metadata_row[\"doi\"]\n",
    "\n",
    "    @property\n",
    "    def url(self):\n",
    "        return self._metadata_row[\"url\"]\n",
    "    \n",
    "    def register_reference(self, reference):\n",
    "        self._references.append(reference)\n",
    "        reference.register_referenced(self)\n",
    "    \n",
    "    def register_referenced(self, referenced):\n",
    "        self._referenced_by.append(referenced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "class PDFPaper(BasePaper):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "class PMCPaper(BasePaper):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def load_papers_from_metadata_file(cord19_dataset_folder):\n",
    "    'Loads papers by reading the `metadata.csv` file present in the dataset.'\n",
    "    metadata_df = pd.read_csv(f\"{cord19_dataset_folder}/metadata.csv\",\n",
    "                              index_col=\"cord_uid\")\n",
    "    \"\"\"\n",
    "    pdf_dict = get_id_paths_dicts(\"pdf\", cord19_dataset_folder)\n",
    "    pmc_dict = get_id_paths_dicts(\"pmc\", cord19_dataset_folder)\n",
    "    \"\"\"\n",
    "\n",
    "    papers = []\n",
    "    # not_found = []\n",
    "    for idx, row in progress_bar(metadata_df.iterrows(),\n",
    "                                 total=len(metadata_df)):\n",
    "        \n",
    "        paper = None\n",
    "        pmc_rel_path = row[\"pmc_json_files\"]\n",
    "        pdf_rel_path = row[\"pdf_json_files\"]\n",
    "        \n",
    "        if pd.notna(pmc_rel_path):\n",
    "            path = os.path.join(cord19_dataset_folder, pmc_rel_path)\n",
    "            paper = PMCPaper(row, path)\n",
    "        \n",
    "        if pd.notna(pdf_rel_path):\n",
    "            path_splitted = pdf_rel_path.split(\"; \")[0]\n",
    "            path = os.path.join(cord19_dataset_folder, path_splitted)\n",
    "            paper = PDFPaper(row, path)\n",
    "        \n",
    "        if paper is not None:\n",
    "            papers.append(paper)\n",
    "\n",
    "    return papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = load_papers_from_metadata_file(cord19_dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(papers)} papers found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_1 = metadata_df[\"pmc_json_files\"].notna()\n",
    "mask_2 = metadata_df[\"pdf_json_files\"].notna()\n",
    "print(\n",
    "    f'There are {(mask_1 | mask_2).sum()} files with either parsed PDF or PMC XML.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peeking at the paper info we just loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "def paper_as_markdown(paper):\n",
    "    from IPython.display import display, Markdown\n",
    "    res = f\"\"\"\n",
    "- **Title:** {paper.title}\n",
    "- **Authors:** {paper.authors}\n",
    "- **Publish date/time:** {paper.publish_time}\n",
    "- **Linked references:** {len(paper._references)}\n",
    "- **Linked referenced by:** {len(paper._referenced_by)}\n",
    "- **Abstract:** {paper.abstract}\"\"\"\n",
    "    display(Markdown(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = random.sample(papers, 1)[0]\n",
    "paper_as_markdown(paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching references to titles\n",
    "\n",
    "We now make the match between the titles (in plain text) of the references of each paper and their titles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dictionary to map titles to papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "def process_references(papers):\n",
    "    paper_titles = {}\n",
    "    for paper in progress_bar(papers):\n",
    "        title = paper.title\n",
    "        if isinstance(title, str):  # coping with NaNs in titles\n",
    "            paper_titles[title.lower()] = paper\n",
    "\n",
    "    num_processed_refs = 0\n",
    "    num_succesfully_processed_refs = 0\n",
    "    for paper in progress_bar(papers):\n",
    "        for _, ref in paper.bib_entries.items():\n",
    "            ref_title = ref[\"title\"].lower()\n",
    "            if ref_title in paper_titles:\n",
    "                paper.register_reference(paper_titles[ref_title])\n",
    "                num_succesfully_processed_refs += 1\n",
    "        num_processed_refs += len(paper.bib_entries)\n",
    "    return num_processed_refs, num_succesfully_processed_refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_processed_refs, num_succesfully_processed_refs = process_references(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total references: {num_processed_refs}.')\n",
    "print(f'References present in the dataset {num_succesfully_processed_refs} ({num_succesfully_processed_refs/num_processed_refs*100}%).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One strategy to mitigate that less than 7% of references are also in the dataset is to create special nodes for the papers outside the set, in this way the structure of the graph is better preserved.\n",
    "\n",
    "On the other hand, other questions must be answered:\n",
    "\n",
    "- How many papers are referenced at least once in the data set?\n",
    "- What are the most referenced papers in the dataset? Long tail?\n",
    "- What are the most referenced papers outside the dataset? Long tail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_references = 0\n",
    "num_referenced_by = 0\n",
    "for paper in papers:\n",
    "    if len(paper._references) > 0:\n",
    "        num_references += 1\n",
    "    if len(paper._referenced_by) > 0:\n",
    "        num_referenced_by += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "\n",
    "- How many papers have at least one referece correctly linked?\n",
    "- How many papers have been references at least once?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total papers: {len(papersld)}.')\n",
    "print(f'Number of references {num_references} ({num_references/len(papers)*100}%).')\n",
    "print(f'Number of referenced-by {num_referenced_by} ({num_referenced_by/len(papers)*100}%).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most reference papers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_sorted = sorted(papers, key=lambda p: len(p._referenced_by), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most cited paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_as_markdown(papers_sorted[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and its refereces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for paper in papers_sorted[0]._references:\n",
    "     paper_as_markdown(paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot time!\n",
    "\n",
    "Note that the dataset includes papers published before the current pandemic started.\n",
    "The following cells will plot the number of references distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_references = sorted([len(paper._references) for paper in papers],\n",
    "                        reverse=True)\n",
    "num_referenced_by = sorted([len(paper._referenced_by) for paper in papers],\n",
    "                           reverse=True)\n",
    "fig = plt.figure(figsize=(11, 8))\n",
    "ax = sns.lineplot(y=num_references, x=range(len(papers)))\n",
    "ax.set(title=\"Correctly linked paper references\", yscale=\"log\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11, 8))\n",
    "ax = sns.lineplot(y=num_referenced_by, x=range(len(papers)))\n",
    "ax.set(title=\"References to papers correclty linked\", yscale=\"log\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot it's concluded that the number of linked references follow a power law, with a tiny bit of them accounting for most of the references.\n",
    "\n",
    "# PageRank\n",
    "\n",
    "The following cells will compute the PageRank score based on the previously built paper references link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def build_papers_reference_graph(papers):\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # First add the nodes\n",
    "    for paper in papers:\n",
    "        G.add_node(paper)\n",
    "    \n",
    "    # Then, add the links\n",
    "    for paper in papers:\n",
    "        for referenced_paper in paper._references:\n",
    "            G.add_edge(paper, referenced_paper)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = build_papers_reference_graph(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_nodes(), G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = nx.pagerank(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_pr = {k: v for k, v in sorted(pr.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-ranked papers in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for paper in list(sorted_pr.keys())[:5]:\n",
    "     paper_as_markdown(paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it can be seen that the papers with the highest PageRank are highly cited and in general are works from past decades that probably constitute the basis of current research against COVID-19.\n",
    "\n",
    "The distribution of PageRank scores will be shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_values = np.array(list(sorted_pr.values()))\n",
    "\n",
    "# Removing outliers\n",
    "pr_mean = np.mean(pr_values)\n",
    "pr_std = np.std(pr_values)\n",
    "pr_distance = abs(pr_values - pr_mean)\n",
    "max_std = 1.5\n",
    "pr_not_outlier = pr_distance < max_std * pr_std\n",
    "pr_no_outliers = pr_values[pr_not_outlier]\n",
    "\n",
    "len(pr_values), len(pr_no_outliers), len(pr_values) - len(pr_no_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11, 8))\n",
    "ax = sns.distplot(pr_values, kde=False, rug=True)\n",
    "ax.set(title=\"Distribution of PageRank of papers including outliers\", yscale=\"log\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11, 8))\n",
    "ax = sns.distplot(pr_no_outliers, kde=False, rug=True)\n",
    "ax.set(title=\"Distribution of PageRank of papers including outliers\", yscale=\"log\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
