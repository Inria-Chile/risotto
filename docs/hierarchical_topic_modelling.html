---

title: Hierarchical Topic Modeling

keywords: fastai
sidebar: home_sidebar

summary: "In this notebook we're going to expand our previous topic modeling approaches in order to model hierarchic topics."
description: "In this notebook we're going to expand our previous topic modeling approaches in order to model hierarchic topics."
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 03_hierarchical_topic_modelling.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div align='left' style="width:29%;overflow:hidden;">
<a href='http://inria.fr'>
{% include image.html alt="Inria logo" title="Inria logo" file="https://github.com/lmarti/jupyter_custom/raw/master/imgs/inr_logo_rouge.png" %}
</a>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Hierarchical-Latent-Dirichlet-Allocation-(hLDA)">Hierarchical Latent Dirichlet Allocation (hLDA)<a class="anchor-link" href="#Hierarchical-Latent-Dirichlet-Allocation-(hLDA)"> </a></h2><p>This technique was presented in the 2004 NeurIPS paper "Hierarchical Topic Models and the Nested Chinese Restaurant Process" by David Blei et al. available at: <a href="https://papers.nips.cc/paper/2466-hierarchical-topic-models-and-the-nested-chinese-restaurant-process.pdf">https://papers.nips.cc/paper/2466-hierarchical-topic-models-and-the-nested-chinese-restaurant-process.pdf</a>.</p>
<p>A quick Google search yields at least two implementations:</p>
<ul>
<li><a href="https://github.com/blei-lab/hlda">https://github.com/blei-lab/hlda</a>: implemented in C by the original authors. Last commit was in 2014.</li>
<li><a href="https://github.com/joewandy/hlda">https://github.com/joewandy/hlda</a>: implemented in Python. Last commit was in 2017.</li>
</ul>
<p>We'll use the second one since it publishes a Jupyter Notebook with an example using the library.
First, we'll install it.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">LatentDirichletAllocation</span>

<span class="kn">from</span> <span class="nn">fastprogress.fastprogress</span> <span class="kn">import</span> <span class="n">progress_bar</span>

<span class="kn">from</span> <span class="nn">risotto.lda</span> <span class="kn">import</span> <span class="n">tokenizer</span>
<span class="kn">from</span> <span class="nn">risotto.references</span> <span class="kn">import</span> <span class="n">load_papers_from_metadata_file</span><span class="p">,</span> <span class="n">paper_as_markdown</span>
<span class="kn">from</span> <span class="nn">risotto.lda</span> <span class="kn">import</span> <span class="n">process_papers_file_contents</span>
<span class="kn">from</span> <span class="nn">risotto.lda</span> <span class="kn">import</span> <span class="n">topic_descriptors</span>
<span class="kn">from</span> <span class="nn">risotto.sampler</span> <span class="kn">import</span> <span class="n">HierarchicalLDA</span>

<span class="kn">import</span> <span class="nn">pickle</span><span class="o">,</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># imports not required by the library</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">vstack</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we'll proceed to load the CORD-19 dataset papers.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">CORD19_DATASET_FOLDER</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;./datasets/CORD-19-research-challenge&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">papers</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">load_papers_from_metadata_file</span><span class="p">(</span><span class="n">CORD19_DATASET_FOLDER</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We've loaded the papers on memory.
Now, we'll process them in order to produce text strings with their contents.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">docs</span> <span class="o">=</span> <span class="n">process_papers_file_contents</span><span class="p">(</span><span class="n">papers</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The last preprocessing step is to vectorize each paper.
We'll represent them using the CountVectorizer <code>scikit-learn</code> implementation.
We purposefully don't use representations such as <code>tf-idf</code> because the LDA algorithm takes care of the document frequency normalization of tokens.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_hlda_corpus</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">max_vocab_size</span><span class="o">=</span><span class="mi">2</span><span class="o">**</span><span class="mi">13</span><span class="p">):</span>
    <span class="n">count_vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">lowercase</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">max_features</span><span class="o">=</span><span class="n">max_vocab_size</span><span class="p">,</span>
    <span class="p">)</span>
    
    <span class="n">count_vectorizer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
    
    <span class="n">vocab</span> <span class="o">=</span> <span class="n">count_vectorizer</span><span class="o">.</span><span class="n">vocabulary_</span>
    <span class="n">docs_tokenized</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">docs_tokens_idxs</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">docs</span><span class="p">):</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">doc</span><span class="p">)]</span>
        <span class="n">idxs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">:</span>
                <span class="n">idxs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab</span><span class="p">[</span><span class="n">token</span><span class="p">])</span>
        <span class="n">docs_tokenized</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
        <span class="n">docs_tokens_idxs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idxs</span><span class="p">)</span>
        
    <span class="n">vocab_list</span> <span class="o">=</span> <span class="n">count_vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">docs_tokenized</span><span class="p">,</span> <span class="n">docs_tokens_idxs</span><span class="p">,</span> <span class="n">vocab_list</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">docs_tokenized</span><span class="p">,</span> <span class="n">docs_tokens_idxs</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">get_hlda_corpus</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>docs_tokenized</code> is a list of lists with the tokenization of each paper.
<code>docs_tokens_idxs</code> is a list of lists with the vocabulary indeces of each paper token.
Finally, <code>vocab</code> is the list with the vocabulary used.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hlda</span> <span class="o">=</span> <span class="n">HierarchicalLDA</span><span class="p">(</span>
    <span class="n">corpus</span><span class="o">=</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">docs_tokens_idxs</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">docs_tokens_idxs</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">)),</span>
    <span class="n">vocab</span><span class="o">=</span><span class="n">vocab</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">gamma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">eta</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">num_levels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hlda</span><span class="o">.</span><span class="n">estimate</span><span class="p">(</span>
    <span class="n">num_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
    <span class="n">display_topics</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">n_words</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">with_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Sampling a 10% of the total papers results in a sub-dataset of about 3.888 papers.
The number of topics of each level is determined by the Chinese Restaurant Process and can be influenced by tweaking the <code>alpha</code> and <code>gamma</code> hyperparameters.
Training the model on the 10% sample took about an hour for each 50 iterations.</p>
<p>To avoid spending time retraining the model, it'll be dumped to be able to load it in posterior experiments.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Dump the model</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;hlda.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">dump_file</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">hlda</span><span class="p">,</span> <span class="n">dump_file</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now, we'll load the dumped model.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Load the model</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;hlda.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">dump_file</span><span class="p">:</span>
    <span class="n">hlda</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">dump_file</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Manual-Hierarchical-LDA">Manual Hierarchical LDA<a class="anchor-link" href="#Manual-Hierarchical-LDA"> </a></h2><p>In this section we'll attempt to manually build a hierarchical topic model.
Essentially, using the same number of topics found by the hLDA technique at <code>level=1</code>, we'll model topics using the standard LDA.
Afterwards, for each group of documents of the first level topics, we'll run a new LDA topic modelling step.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_lda_corpus</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">max_vocab_size</span><span class="o">=</span><span class="mi">2</span><span class="o">**</span><span class="mi">13</span><span class="p">):</span>
    <span class="n">count_vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">lowercase</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">max_features</span><span class="o">=</span><span class="n">max_vocab_size</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">vectorized_docs</span> <span class="o">=</span> <span class="n">count_vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">vectorized_docs</span><span class="p">,</span> <span class="n">count_vectorizer</span>


<span class="k">def</span> <span class="nf">fit_lda_model</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">vectorized_docs</span><span class="p">,</span> <span class="n">count_vectorizer</span> <span class="o">=</span> <span class="n">get_lda_corpus</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
    <span class="n">lda</span> <span class="o">=</span> <span class="n">LatentDirichletAllocation</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">lda</span> <span class="o">=</span> <span class="n">lda</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">vectorized_docs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lda</span><span class="p">,</span> <span class="n">vectorized_docs</span><span class="p">,</span> <span class="n">count_vectorizer</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_lda_corpus" class="doc_header"><code>get_lda_corpus</code><a href="https://github.com/lmarti/risotto/tree/master/risotto/hierarchical_lda.py#L23" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_lda_corpus</code>(<strong><code>docs</code></strong>, <strong><code>max_vocab_size</code></strong>=<em><code>8192</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="fit_lda_model" class="doc_header"><code>fit_lda_model</code><a href="https://github.com/lmarti/risotto/tree/master/risotto/hierarchical_lda.py#L33" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>fit_lda_model</code>(<strong><code>docs</code></strong>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lda</span><span class="p">,</span> <span class="n">vectorized_docs</span><span class="p">,</span> <span class="n">count_vectorizer</span> <span class="o">=</span> <span class="n">fit_lda_model</span><span class="p">(</span>
    <span class="n">docs</span><span class="p">,</span>
    <span class="n">n_components</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The following cell will print the most relevant tokens of each modelled component.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">topic_descriptors</span><span class="p">(</span><span class="n">lda</span><span class="p">,</span> <span class="n">count_vectorizer</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now, we'll build the groups of papers belonging to the different modelled topics.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">group_docs_by_topics</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">vectorized_docs</span><span class="p">):</span>
    <span class="n">docs_classified</span> <span class="o">=</span> <span class="n">lda</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">vectorized_docs</span><span class="p">)</span>
    <span class="n">docs_topics</span> <span class="o">=</span> <span class="n">docs_classified</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">clustered_docs</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">vectorized_doc</span><span class="p">,</span> <span class="n">topic_idx</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">vectorized_docs</span><span class="p">,</span> <span class="n">docs_topics</span><span class="p">):</span>
        <span class="n">clustered_docs</span><span class="p">[</span><span class="n">topic_idx</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vectorized_doc</span><span class="p">)</span>

    <span class="n">stacked_clustered_docs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">topic_idx</span><span class="p">,</span> <span class="n">docs_list</span> <span class="ow">in</span> <span class="n">clustered_docs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">stacked_clustered_docs</span><span class="p">[</span><span class="n">topic_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">vstack</span><span class="p">(</span><span class="n">docs_list</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">stacked_clustered_docs</span>

<span class="n">grouped_docs</span> <span class="o">=</span> <span class="n">group_docs_by_topics</span><span class="p">(</span><span class="n">lda</span><span class="p">,</span> <span class="n">vectorized_docs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">grouped_docs</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then, for each paper group, we'll run LDA on them.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">topic_descriptors</span><span class="p">(</span><span class="n">lda</span><span class="p">,</span> <span class="n">count_vectorizer</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="n">models</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">topic_idx</span><span class="p">,</span> <span class="n">group_docs</span> <span class="ow">in</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">grouped_docs</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Topic ID #</span><span class="si">{</span><span class="n">topic_idx</span><span class="si">}</span><span class="s2">; documents = </span><span class="si">{</span><span class="n">group_docs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="n">models</span><span class="p">[</span><span class="n">topic_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">LatentDirichletAllocation</span><span class="p">(</span>
        <span class="n">n_components</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">models</span><span class="p">[</span><span class="n">topic_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="n">topic_idx</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">group_docs</span><span class="p">)</span>
    
    <span class="n">topic_descriptors</span><span class="p">(</span><span class="n">models</span><span class="p">[</span><span class="n">topic_idx</span><span class="p">],</span> <span class="n">count_vectorizer</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
</div>
 

