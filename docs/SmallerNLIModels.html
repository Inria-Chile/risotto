---

title: Read this!

keywords: fastai
sidebar: home_sidebar



---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 08_SmallerNLIModels.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">env</span> CUDA_VISIBLE_DEVICES=6
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>env: CUDA_VISIBLE_DEVICES=6
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Natural-Language-Inference-(NLI)-method">Natural Language Inference (NLI) method<a class="anchor-link" href="#Natural-Language-Inference-(NLI)-method"> </a></h2><p>In this approach we use a BART classifier (Lewis et al., 2019) pre-trained on the Multi-Genre NLI (MultiNLI, Williams et al., 2018) corpus as the base model.</p>
<p>Given research interests expressed in natural language, we pose the problem of recovering relevant research from the CORD-19 dataset (Wang et al., 2020) as a Zero Shot Topic Classification task (Yin et al., 2019).
Leveraging the Natural Language Inference task framework, we assess each paper relevance by feeding the model with the paper's title and abstract as premise and a research interest as hypothesis.</p>
<p>Finally, we use the model's entailment inference values as proxy relevance scores for each paper.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_nli_model" class="doc_header"><code>get_nli_model</code><a href="__main__.py#L7" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_nli_model</code>(<strong><code>name</code></strong>=<em><code>'facebook/bart-large-mnli'</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">risotto.artifacts</span> <span class="kn">import</span> <span class="n">load_papers_artifact</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">papers</span> <span class="o">=</span> <span class="n">load_papers_artifact</span><span class="p">()</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">get_nli_model</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;huggingface/prunebert-base-uncased-6-finepruned-w-distil-mnli&quot;</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">FileNotFoundError</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Data artifacts not ready.&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/lmarti/.pyenv/versions/3.8.2/envs/risotto/lib/python3.8/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.
  warnings.warn(msg)
/Users/lmarti/.pyenv/versions/3.8.2/envs/risotto/lib/python3.8/site-packages/spacy/util.py:271: UserWarning: [W031] Model &#39;en_core_sci_sm&#39; (0.2.4) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.0). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate
  warnings.warn(warn_msg)
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Data artifacts not ready.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="build_tokenized_papers_artifact" class="doc_header"><code>build_tokenized_papers_artifact</code><a href="__main__.py#L7" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>build_tokenized_papers_artifact</code>(<strong><code>papers</code></strong>, <strong><code>tokenizer</code></strong>, <strong><code>should_dump</code></strong>=<em><code>True</code></em>, <strong><code>dump_path</code></strong>=<em><code>None</code></em>, <strong><code>batch_size</code></strong>=<em><code>128</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="load_tokenized_papers_artifact" class="doc_header"><code>load_tokenized_papers_artifact</code><a href="__main__.py#L34" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>load_tokenized_papers_artifact</code>(<strong><code>artifacts_path</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenized_papers</span> <span class="o">=</span> <span class="n">build_tokenized_papers_artifact</span><span class="p">(</span>
    <span class="n">papers</span><span class="o">=</span><span class="n">papers</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">dump_path</span><span class="o">=</span><span class="s2">&quot;artifacts/nli_bert_artifacts.hdf&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">tokenized_papers</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      <progress value='604' class='' max='604' style='width:300px; height:20px; vertical-align: middle;'></progress>
      100.00% [604/604 12:49<00:00]
    </div>
    
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/lmarti/risotto/venv-risotto/lib/python3.7/site-packages/pandas/core/generic.py:2505: PerformanceWarning: 
your performance may suffer as PyTables will pickle object types that it cannot
map directly to c-types [inferred_type-&gt;mixed,key-&gt;values] [items-&gt;None]

  encoding=encoding,
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>ug7v899j    [101, 6612, 2838, 1997, 3226, 1011, 10003, 202...
02tnwd4m    [101, 9152, 12412, 15772, 1024, 1037, 4013, 10...
ejv2xln0    [101, 14175, 18908, 4630, 5250, 1011, 1040, 19...
2b73a28n    [101, 2535, 1997, 2203, 14573, 18809, 1011, 10...
9785vg6d    [101, 4962, 3670, 1999, 4958, 8939, 24587, 444...
Name: tokenized_papers, dtype: object</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenized_papers</span> <span class="o">=</span> <span class="n">load_tokenized_papers_artifact</span><span class="p">(</span>
    <span class="s2">&quot;artifacts/nli_bert_artifacts.hdf&quot;</span><span class="p">)</span>
<span class="n">tokenized_papers</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>ug7v899j    [0, 20868, 1575, 9, 2040, 12, 32012, 1308, 438...
02tnwd4m    [0, 19272, 4063, 30629, 35, 10, 1759, 12, 3382...
ejv2xln0    [0, 6544, 24905, 927, 8276, 12, 495, 8, 34049,...
2b73a28n    [0, 21888, 9, 253, 15244, 2614, 12, 134, 11, 1...
9785vg6d    [0, 13120, 8151, 11, 22201, 44828, 4590, 11, 1...
Name: tokenized_papers, dtype: object</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="build_entailments_artifact" class="doc_header"><code>build_entailments_artifact</code><a href="__main__.py#L6" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>build_entailments_artifact</code>(<strong><code>tokenized_papers</code></strong>, <strong><code>query_tokenized</code></strong>, <strong><code>batch_size</code></strong>=<em><code>64</code></em>, <strong><code>device</code></strong>=<em><code>'cuda'</code></em>, <strong><code>should_dump</code></strong>=<em><code>True</code></em>, <strong><code>dump_path</code></strong>=<em><code>None</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="load_entailments_artifact" class="doc_header"><code>load_entailments_artifact</code><a href="__main__.py#L78" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>load_entailments_artifact</code>(<strong><code>artifacts_path</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">query_tokenized</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
    <span class="s2">&quot;This paper is about vaccines and therapeutics.&quot;</span><span class="p">)</span>
<span class="n">build_entailments_artifact</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                           <span class="n">tokenized_papers</span><span class="o">=</span><span class="n">tokenized_papers</span><span class="p">,</span>
                           <span class="n">query_tokenized</span><span class="o">=</span><span class="n">query_tokenized</span><span class="p">,</span>
                           <span class="n">dump_path</span><span class="o">=</span><span class="s2">&quot;artifacts/nli_bert_artifacts.hdf&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

    <div>
        <style>
            /* Turns off some styling */
            progress {
                /* gets rid of default border in Firefox and Opera. */
                border: none;
                /* Needs to be in here for Safari polyfill so background images work as expected. */
                background-size: auto;
            }
            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
                background: #F44336;
            }
        </style>
      <progress value='302' class='' max='302' style='width:300px; height:20px; vertical-align: middle;'></progress>
      100.00% [302/302 18:46<00:00]
    </div>
    
</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>ug7v899j    34.904873
02tnwd4m     3.709159
ejv2xln0    83.782410
2b73a28n     0.407605
9785vg6d    83.543762
              ...    
2upc2spn    72.468544
48kealmj    21.194389
7goz1agp    90.725761
twp49jg3    78.526169
wtoj53xy    10.045611
Name: entailments, Length: 77304, dtype: float64</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="References">References<a class="anchor-link" href="#References"> </a></h2><p>Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., … Amodei, D. (2020). Language Models are Few-Shot Learners. <a href="https://arxiv.org/abs/2005.14165">https://arxiv.org/abs/2005.14165</a></p>
<p>Davison, J. (2020). Zero-Shot Learning in Modern NLP. <a href="https://joeddav.github.io/blog/2020/05/29/ZSL.html">https://joeddav.github.io/blog/2020/05/29/ZSL.html</a></p>
<p>Lewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O., Stoyanov, V., &amp; Zettlemoyer, L. (2019). BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension. <a href="http://arxiv.org/abs/1910.13461">http://arxiv.org/abs/1910.13461</a></p>
<p>Reimers, N., &amp; Gurevych, I. (2020). Sentence-BERT: Sentence embeddings using siamese BERT-networks. EMNLP-IJCNLP 2019 - 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, Proceedings of the Conference, 3982–3992. <a href="https://doi.org/10.18653/v1/d19-1410">https://doi.org/10.18653/v1/d19-1410</a></p>
<p>Veeranna, S. P., Nam, J., Mencía, E. L., &amp; Fürnkranz, J. (2016). Using semantic similarity for multi-label zero-shot classification of text documents. ESANN 2016 - 24th European Symposium on Artificial Neural Networks, April, 423–428.</p>
<p>Wang, L. L., Lo, K., Chandrasekhar, Y., Reas, R., Yang, J., Eide, D., Funk, K., Kinney, R., Liu, Z., Merrill, W., Mooney, P., Murdick, D., Rishi, D., Sheehan, J., Shen, Z., Stilson, B., Wade, A. D., Wang, K., Wilhelm, C., … Kohlmeier, S. (2020). CORD-19: The Covid-19 Open Research Dataset. <a href="https://arxiv.org/abs/2004.10706">https://arxiv.org/abs/2004.10706</a></p>
<p>Williams, A., Nangia, N., &amp; Bowman, S. R. (2018). A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference. Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), 1112--1122. <a href="http://aclweb.org/anthology/N18-1101">http://aclweb.org/anthology/N18-1101</a></p>
<p>Yin, W., Hay, J., &amp; Roth, D. (2019). Benchmarking zero-shot text classification: Datasets, evaluation and entailment approach. EMNLP-IJCNLP 2019 - 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, Proceedings of the Conference, 3914–3923. <a href="https://doi.org/10.18653/v1/d19-1404">https://doi.org/10.18653/v1/d19-1404</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
</div>
 

